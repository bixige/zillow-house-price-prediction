{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from catboost import CatBoostRegressor\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "properties2016 = pd.read_csv('/Users/KUANGBixi/Downloads/properties_2016.csv', low_memory = False)\n",
    "properties2017 = pd.read_csv('/Users/KUANGBixi/Downloads/properties_2017.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train2016 = pd.read_csv('/Users/KUANGBixi/Downloads/train_2016_v2.csv', parse_dates=['transactiondate'], low_memory=False)\n",
    "train2017 = pd.read_csv('/Users/KUANGBixi/Downloads/train_2017.csv', parse_dates=['transactiondate'], low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_date_features(df):\n",
    "    df[\"transaction_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transaction_month\"] = (df[\"transactiondate\"].dt.year - 2016)*12 + df[\"transactiondate\"].dt.month\n",
    "    df[\"transaction_day\"] = df[\"transactiondate\"].dt.day\n",
    "    df[\"transaction_quarter\"] = (df[\"transactiondate\"].dt.year - 2016)*4 +df[\"transactiondate\"].dt.quarter\n",
    "    df.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train2016 = add_date_features(train2016)\n",
    "train2017 = add_date_features(train2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('/Users/KUANGBixi/Downloads/sample_submission-3.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train2016 = pd.merge(train2016, properties2016, how = 'left', on = 'parcelid')\n",
    "train2017 = pd.merge(train2017, properties2017, how = 'left', on = 'parcelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([train2016, train2017], axis = 0)\n",
    "test_df = pd.merge(sample_submission[['ParcelId']], properties2016.rename(columns = {'parcelid': 'ParcelId'}), how = 'left', on = 'ParcelId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del properties2016, properties2017, train2016, train2017\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_feature = ['heatingorsystemtypeid','propertylandusetypeid', 'storytypeid', 'airconditioningtypeid',\n",
    "        'architecturalstyletypeid', 'buildingclasstypeid', 'buildingqualitytypeid', 'typeconstructiontypeid']\n",
    "for c in train_df.columns:\n",
    "        train_df[c]=train_df[c].fillna(-999)\n",
    "        if train_df[c].dtype == 'object':\n",
    "            lbl = LabelEncoder()\n",
    "            lbl.fit(list(train_df[c].values))\n",
    "            train_df[c] = lbl.transform(list(train_df[c].values))\n",
    "        if c in id_feature:\n",
    "            lbl = LabelEncoder()\n",
    "            lbl.fit(list(train_df[c].values))\n",
    "            train_df[c] = lbl.transform(list(train_df[c].values))\n",
    "            dum_df = pd.get_dummies(train_df[c])\n",
    "            dum_df = dum_df.rename(columns=lambda x:c+str(x))\n",
    "            train_df = pd.concat([train_df,dum_df],axis=1)\n",
    "            train_df = train_df.drop([c], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_feature = ['heatingorsystemtypeid','propertylandusetypeid', 'storytypeid', 'airconditioningtypeid',\n",
    "        'architecturalstyletypeid', 'buildingclasstypeid', 'buildingqualitytypeid', 'typeconstructiontypeid']\n",
    "for c in test_df.columns:\n",
    "        test_df[c]=test_df[c].fillna(-999)\n",
    "        if test_df[c].dtype == 'object':\n",
    "            lbl = LabelEncoder()\n",
    "            lbl.fit(list(test_df[c].values))\n",
    "            test_df[c] = lbl.transform(list(test_df[c].values))\n",
    "        if c in id_feature:\n",
    "            lbl = LabelEncoder()\n",
    "            lbl.fit(list(test_df[c].values))\n",
    "            test_df[c] = lbl.transform(list(test_df[c].values))\n",
    "            dum_df = pd.get_dummies(test_df[c])\n",
    "            dum_df = dum_df.rename(columns=lambda x:c+str(x))\n",
    "            test_df = pd.concat([test_df,dum_df],axis=1)\n",
    "            test_df = test_df.drop([c], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop outliers\n",
    "train_df = train_df[train_df.logerror > -0.4]\n",
    "train_df = train_df[train_df.logerror < 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#exclude percentage of missing value > 98%\n",
    "missing_perc_thresh = 0.98 \n",
    "exclude_missing = []\n",
    "num_rows = train_df.shape[0]\n",
    "for c in train_df.columns:\n",
    "    num_missing = train_df[c].isnull().sum()\n",
    "    if num_missing == 0:\n",
    "        continue\n",
    "    missing_frac = num_missing / float(num_rows)\n",
    "    if missing_frac > missing_perc_thresh:\n",
    "        exclude_missing.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del num_rows, missing_perc_thresh\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#exclude unique value\n",
    "exclude_unique = [] \n",
    "for c in train_df.columns:\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if train_df[c].isnull().sum() != 0: #exclude nan value\n",
    "        num_uniques -= 1\n",
    "    if num_uniques == 1:\n",
    "        exclude_unique.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#exclude other features did not influent logerror\n",
    "exclude_other = ['parcelid', 'logerror','propertyzoningdesc', 'propertycountylandusecode'] \n",
    "train_features = []\n",
    "for c in train_df.columns:\n",
    "    if c not in exclude_missing \\\n",
    "       and c not in exclude_other and c not in exclude_unique:\n",
    "        train_features.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.fillna(-999, inplace=True)\n",
    "test_df.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_df[train_features]\n",
    "y_train = train_df.logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['transactiondate'] = pd.Timestamp('2016-12-01') \n",
    "test_df = add_date_features(test_df)\n",
    "X_test = test_df[train_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KUANGBixi/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/KUANGBixi/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=100).split(X_train.values, y_train)\n",
    "    rmse= -cross_val_score(model, X_train.values, y_train, scoring=\"mean_absolute_error\", cv = kf)\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb = LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extra = ExtraTreesRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "de = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada = AdaBoostRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(xgb)\n",
    "print(\"\\nxgb score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(random)\n",
    "print(\"\\nrandom score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(lgb)\n",
    "print(\"\\nlgb score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(extra)\n",
    "print(\"\\nextra score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(de)\n",
    "print(\"\\nde score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(ada)\n",
    "print(\"\\nada score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestRegressor(n_estimators=60), \n",
    "   param_grid = param_test1, scoring='mean_absolute_error', cv=10)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_test2 = {'max_depth':[6, 8, 10, 12], 'min_samples_split':[80, 100, 120, 140]}\n",
    "gsearch2 = GridSearchCV(estimator = RandomForestRegressor(n_estimators=60), \n",
    "   param_grid = param_test2, scoring='mean_absolute_error', cv=10)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_params = {}\n",
    "rf_params['n_estimators'] = 60\n",
    "rf_params['max_depth'] = 6\n",
    "rf_params['min_samples_split'] = 80\n",
    "rf_params['min_samples_leaf'] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random = RandomForestRegressor(**rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.fit(X_train, y_train)\n",
    "y_pred = random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ParcelId': test_df['ParcelId'],})\n",
    "test_dates = {\n",
    "    '201610': pd.Timestamp('2016-09-30'),\n",
    "    '201611': pd.Timestamp('2016-10-31'),\n",
    "    '201612': pd.Timestamp('2016-11-30'),\n",
    "    '201710': pd.Timestamp('2017-09-30'),\n",
    "    '201711': pd.Timestamp('2017-10-31'),\n",
    "    '201712': pd.Timestamp('2017-11-30')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for: 201610 ... \n",
      "Predicting for: 201611 ... \n",
      "Predicting for: 201612 ... \n",
      "Predicting for: 201710 ... \n",
      "Predicting for: 201711 ... \n",
      "Predicting for: 201712 ... \n"
     ]
    }
   ],
   "source": [
    "for label, test_date in test_dates.items():\n",
    "    submission[label] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"random_newparams.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('random_newparams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParcelId</th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "      <th>201710</th>\n",
       "      <th>201711</th>\n",
       "      <th>201712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.004998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>-0.015584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.002773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.002285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ParcelId    201610    201611    201612    201710    201711    201712\n",
       "0  10754147 -0.004998 -0.004998 -0.004998 -0.004998 -0.004998 -0.004998\n",
       "1  10759547 -0.015584 -0.015584 -0.015584 -0.015584 -0.015584 -0.015584\n",
       "2  10843547  0.000953  0.000953  0.000953  0.000953  0.000953  0.000953\n",
       "3  10859147  0.002773  0.002773  0.002773  0.002773  0.002773  0.002773\n",
       "4  10879947  0.002285  0.002285  0.002285  0.002285  0.002285  0.002285"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
